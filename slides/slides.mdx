import { Notes, Steps } from "mdx-deck";
import { CodeSurfer } from "code-surfer";
import { nightOwl } from "@code-surfer/themes";
import "prismjs/components/prism-ruby";

export const theme = nightOwl;

# Ruby 3+ Concurrency

- How does Ruby handle Concurrency?
- Why is Ruby 3+ an improvement?

---

# All of the acronyms

<div style={{ display: 'flex' }}>
  <div>
    <ul>
      <li><b>GIL</b>: Global Interpreter Lock</li>
      <li><b>GVL</b>: Global VM Lock</li>
      <li><b>I/O</b>: Input/Output</li>
    </ul>
  </div>
  <div>
    <ul>
      <li><b>YARV</b>: Yet Another Ruby VM</li>
      <li><b>MRI</b>: Matz's Ruby Interpreter</li>
    </ul>
  </div>
</div>

---

# What is the GVL?

- Global Virtual Machine Lock
- One native thread executed at a time
- Design detail of MRI

<Notes>
  - May be familiar with GIL
  - Now GVL thanks to YARV (Yet Another Ruby VM), Ruby 1.9
  - The Ruby interpreter is limited to one thread of execution, even on a multi-core processor
  - Not all Ruby interpreters have this limitation, e.g. TruffleRuby, JRuby, etc.
</Notes>

---

# GVL Pros

- Faster single-thread execution
- Easier integration of C libraries
- Ease of implementation

<Notes>
  - If we can't interpret code in parallel, we don't need to worry about it!
  - There are so many C Ruby extensions because that work can be run outside of the GVL, utilizing multi-core processors.
</Notes>

---

# GVL Cons

- **Concurrency is limited to blocking operations only**
- No parallel execution of interpreted code

<Notes>
  - In other words, you cannot use Ruby Threads to execute interpreted code in parallel
</Notes>

---

# No parallel execution of interpreted code

<CodeSurfer>

```rb
def fib(n) =
  n < 2 ? n : fib(n-1) + fib(n-2)
```

```rb 4 title="Run 4 times, sequentially"
def fib(n) =
  n < 2 ? n : fib(n-1) + fib(n-2)

4.times { fib(24) }
```

```rb 4:7 title="Still running 4 times sequentially"
def fib(n) =
  n < 2 ? n : fib(n-1) + fib(n-2)

4.times.map do
  Thread.new { fib(24) }
end
  .each(&:join)
```

</CodeSurfer>

---

# Design Consequences

- Focus on process utilization!
- Spend less time waiting, more time doing.
- Blocking I/O only.

<Notes>
  - Blocking I/O: anything that doesn't directly use CPU cycles from its thread, but instead delegates the work to an external process.
  - e.g. HTTP requests, database queries, reading a file.
</Notes>

---

# Basically, threads

<CodeSurfer>

```rb
%w[2.5 2.6 3.0].map do |v|
  open("https://rubyapi.org/#{v}")
end
```

```rb 2:4 title="Wrap each operation in a Thread"
%w[2.5 2.6 3.0].map do |v|
  Thread.new do
    open("https://rubyapi.org/#{v}")
  end
end
  .each(&:join)
```

```rb 6 title="Pause the main thread and wait for the Threads to finish"
%w[2.5 2.6 3.0].map do |v|
  Thread.new do
    open("https://rubyapi.org/#{v}")
  end
end
  .each(&:join)
```

</CodeSurfer>

---

# What's going on here?

- API calls are blocking I/O
- Ruby freely switches threads when blocked
- `Thread#join` waits until everything finishes

---

# Threads are preemptive

- Programmers don't handle scheduling, Ruby does
- More accurately, Ruby lets the OS handle scheduling
- The cost? Context switching penalties

<Notes>
  - We just tell Ruby to wait and it magically handles stuff for us.
  - That's nice, but it puts the responsibility of thread management to the OS.
  - A context switch is the process of storing the state of a process or thread, so that it can be restored and resume execution at a later point.
</Notes>

---

# Enter: Fibers

- Lighter-weight than Threads
- Cooperative, not preemptive
- No context switching

<Notes>
  - Cooperative: control must be handled manually by the program by yielding control.
  - Fiber overhead is lower so you can run more of them.
  - Previously, rarely used since you have to manually write scheduling logic.
  - Ruby 3.0 introduces a scheduling interface that allows the runtime to manage Fibers more easily, opening them to broader use.
</Notes>

---

# What is a Fiber?

<CodeSurfer>

```rb title="Create a new fiber within the current Thread"
fac = Fiber.new do
end
```

```rb title="Fill in the application logic"
fac = Fiber.new do
  n = 1

  loop do
    rst = (1..n).inject(:*)
    n += 1
  end
end
```

```rb 6 title="Yield control to the main thread"
fac = Fiber.new do
  n = 1

  loop do
    rst = (1..n).inject(:*)
    Fiber.yield(rst)
    n += 1
  end
end
```

```rb title="Resume at the point where the last yield was called"
fac = Fiber.new do
  n = 1

  loop do
    rst = (1..n).inject(:*)
    Fiber.yield(rst)
    n += 1
  end
end

fac.resume
# 1
```

```rb title="Resume at the point where the last yield was called"
fac = Fiber.new do
  n = 1

  loop do
    rst = (1..n).inject(:*)
    Fiber.yield(rst)
    n += 1
  end
end

fac.resume
# 1
fac.resume
# 2
```

```rb title="Resume at the point where the last yield was called"
fac = Fiber.new do
  n = 1

  loop do
    rst = (1..n).inject(:*)
    Fiber.yield(rst)
    n += 1
  end
end

fac.resume
# 1
fac.resume
# 2
fac.resume
# 6
```

</CodeSurfer>

---

# Yeah, but what about concurrency?

1. When a Fiber hits a blocking operation, yield control to other Fibers
2. When the I/O is ready, resume the Fiber
3. ???
4. Profit

<Notes>
  - When a Fiber hits a blocking operation, we yield the I/O we're waiting for.
  - When it's ready, we resume the Fiber and continue where we leave off.
</Notes>

---

# Ruby Fibers are not a new thing

---

# Ruby 3 introduces Non-blocking Fibers

[Original feature request](https://bugs.ruby-lang.org/issues/16786)

<Notes>
  - Fibers are not a new Ruby primitive.
  - Ruby stdlib blocking I/O is now Fiber-aware
  - Scheduler handles yielding/resuming of Fibers
</Notes>

---

# Non-blocking Fibers

<CodeSurfer>

```rb
%w[pikachu squirtle].each do |name|
  URI.open "https://pokeapi.co/api/v2/pokemon/#{name}"
end
```

```rb title="Run the block in a non-blocking Fiber"
%w[pikachu squirtle].each do |name|
  Fiber.schedule do
    URI.open "https://pokeapi.co/api/v2/pokemon/#{name}"
  end
end
```

```rb title="Bring in a Fiber Scheduler"
require "fiber_scheduler"

Fiber.set_scheduler FiberScheduler.new

%w[pikachu squirtle].each do |name|
  Fiber.schedule do
    URI.open "https://pokeapi.co/api/v2/pokemon/#{name}"
  end
end
```

```rb 1,3,5,7,9 title="Or, use a dedicated gem"
require "async"

Async.do |task|
  %w[pikachu squirtle].each do |name|
    task.async do
      URI.open "https://pokeapi.co/api/v2/pokemon/#{name}"
    end
  end
end
```

</CodeSurfer>

---

# BYOSI

- Bring Your Own Scheduling Interface
- Ruby stdlib doesn't provide one by default

---

# Summarized, Why Fibers?

- Lighter-weight than Threads
- Spin up more Fibers on the same system
- Less context switching
- SchedulerInterface = Ruby stdlib compatibility
