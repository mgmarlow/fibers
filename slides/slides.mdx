import { Notes, Steps } from "mdx-deck";
import { CodeSurfer } from "code-surfer";
import { nightOwl } from "@code-surfer/themes";
import "prismjs/components/prism-ruby";
import ioChanges from './io-changes.png'

export const theme = nightOwl;

# Ruby 3+ Concurrency

- How does Ruby handle Concurrency?
- Why is Ruby 3+ an improvement?

---

# All of the acronyms

<div style={{ display: 'flex' }}>
  <div>
    <ul>
      <li><b>GIL</b>: Global Interpreter Lock</li>
      <li><b>GVL</b>: Global VM Lock</li>
      <li><b>I/O</b>: Input/Output</li>
    </ul>
  </div>
  <div>
    <ul>
      <li><b>YARV</b>: Yet Another Ruby VM</li>
      <li><b>MRI</b>: Matz's Ruby Interpreter</li>
    </ul>
  </div>
</div>

---

# What is the GVL?

- Global Virtual Machine Lock
- One native thread executed at a time
- Design detail of MRI

<Notes>
  - May be familiar with GIL
  - Now GVL thanks to YARV (Yet Another Ruby VM), Ruby 1.9
  - The Ruby interpreter is limited to one thread of execution, even on a multi-core processor
  - Not all Ruby interpreters have this limitation, e.g. TruffleRuby, JRuby, etc.
  - When you spin up a bunch of threads in an MRI process and one of those threads wants to interpret some Ruby code, it needs to hold onto the GVL. Only one thread can hold onto the GVL at any given time, so all of the other threads need to wait their turn.
</Notes>

---

# GVL Pros

- Faster single-thread execution
- Easier integration of C libraries
- Protect MRI from race conditions

<Notes>
  - If we can't interpret code in parallel, we don't need to worry about it!
  - There are so many C Ruby extensions because that work can be run outside of the GVL, utilizing multi-core processors.
</Notes>

---

# GVL Cons

- **Concurrency is limited to blocking operations only**
- No parallel execution of interpreted code
- Still doesn't guarantee thread-safe code

<Notes>
  - In other words, you cannot use Ruby Threads to execute interpreted code in parallel
</Notes>

---

# Concurrent, not parallel

<CodeSurfer>

```rb
def tarai(x, y, z) =
  x <= y ? y : tarai(tarai(x-1, y, z),
                     tarai(y-1, z, x),
                     tarai(z-1, x, y))
```

```rb 6 title="Run 4 times, sequentially"
def tarai(x, y, z) =
  x <= y ? y : tarai(tarai(x-1, y, z),
                     tarai(y-1, z, x),
                     tarai(z-1, x, y))

4.times { tarai(14, 7, 0) }
```

```rb 6:9 title="Still running 4 times sequentially"
def tarai(x, y, z) =
  x <= y ? y : tarai(tarai(x-1, y, z),
                     tarai(y-1, z, x),
                     tarai(z-1, x, y))

4.times.map do
  Thread.new { tarai(14,7,0) }
end
  .each(&:join)
```

</CodeSurfer>

---

# Design Consequences

- Focus on process utilization!
- Spend less time waiting, more time doing.
- Blocking I/O only.

<Notes>
  - Blocking I/O: anything that doesn't directly use CPU cycles from its thread, but instead delegates the work to an external process.
  - e.g. HTTP requests, database queries, reading a file.
</Notes>

---

# Basically, threads

<CodeSurfer>

```rb
%w[2.5 2.6 3.0].map do |v|
  open("https://rubyapi.org/#{v}")
end
```

```rb 2:4 title="Wrap each operation in a Thread"
%w[2.5 2.6 3.0].map do |v|
  Thread.new do
    open("https://rubyapi.org/#{v}")
  end
end
  .each(&:join)
```

```rb 6 title="Pause the main thread and wait for the Threads to finish"
%w[2.5 2.6 3.0].map do |v|
  Thread.new do
    open("https://rubyapi.org/#{v}")
  end
end
  .each(&:join)
```

</CodeSurfer>

---

# What's going on here?

- API calls are blocking I/O
- Ruby freely switches threads when blocked
- `Thread#join` waits until everything finishes

---

# Threads are preemptive

- Programmers don't handle scheduling, Ruby does
- More accurately, Ruby lets the OS handle scheduling
- The cost? Context switching penalties

<Notes>
  - We just tell Ruby to wait and it magically handles stuff for us.
  - That's nice, but it puts the responsibility of thread management to the OS.
  - A context switch is the process of storing the state of a process or thread, so that it can be restored and resume execution at a later point.
  - More threads isn't necessarily faster! There's a tradeoff between process overhead and concurrency.
</Notes>

---

# Demo: Thread Safety

---

# Enter: Fibers

- Lighter-weight than Threads
- Cooperative, not preemptive
- No context switching

<Notes>
  - Cooperative: control must be handled manually by the program by yielding control.
  - Fiber overhead is lower so you can run more of them.
  - Previously, rarely used since you have to manually write scheduling logic.
  - Ruby 3.0 introduces a scheduling interface that allows the runtime to manage Fibers more easily, opening them to broader use.
</Notes>

---

# What is a Fiber?

<CodeSurfer>

```rb title="Create a new fiber within the current Thread"
fac = Fiber.new do
end
```

```rb title="Fill in the application logic"
fac = Fiber.new do
  n = 1

  loop do
    rst = (1..n).inject(:*)
    n += 1
  end
end
```

```rb 6 title="Yield control to the main thread"
fac = Fiber.new do
  n = 1

  loop do
    rst = (1..n).inject(:*)
    Fiber.yield(rst)
    n += 1
  end
end
```

```rb title="Resume at the point where the last yield was called"
fac = Fiber.new do
  n = 1

  loop do
    rst = (1..n).inject(:*)
    Fiber.yield(rst)
    n += 1
  end
end

fac.resume
# 1
```

```rb title="Resume at the point where the last yield was called"
fac = Fiber.new do
  n = 1

  loop do
    rst = (1..n).inject(:*)
    Fiber.yield(rst)
    n += 1
  end
end

fac.resume
# 1
fac.resume
# 2
```

```rb title="Resume at the point where the last yield was called"
fac = Fiber.new do
  n = 1

  loop do
    rst = (1..n).inject(:*)
    Fiber.yield(rst)
    n += 1
  end
end

fac.resume
# 1
fac.resume
# 2
fac.resume
# 6
```

</CodeSurfer>

---

# Yeah, but what about concurrency?

1. When a Fiber hits a blocking operation, yield control to other Fibers
2. When the I/O is ready, resume the Fiber
3. ???
4. Profit

<Notes>
  - When a Fiber hits a blocking operation, we yield the I/O we're waiting for.
  - When it's ready, we resume the Fiber and continue where we leave off.
</Notes>

---

# Ruby Fibers are not a new thing

---

# Ruby 3 introduces Non-blocking Fibers

[Original feature request](https://bugs.ruby-lang.org/issues/16786)

<Notes>
  - Fibers are not a new Ruby primitive.
  - Ruby stdlib blocking I/O is now Fiber-aware
  - Scheduler handles yielding/resuming of Fibers
</Notes>

---

# Non-blocking Fibers

<CodeSurfer>

```rb
%w[pikachu squirtle].each do |name|
  URI.open "https://pokeapi.co/api/v2/pokemon/#{name}"
end
```

```rb title="Run the block in a non-blocking Fiber"
%w[pikachu squirtle].each do |name|
  Fiber.schedule do
    URI.open "https://pokeapi.co/api/v2/pokemon/#{name}"
  end
end
```

```rb title="Bring in a Fiber Scheduler"
require "fiber_scheduler"

Fiber.set_scheduler FiberScheduler.new

%w[pikachu squirtle].each do |name|
  Fiber.schedule do
    URI.open "https://pokeapi.co/api/v2/pokemon/#{name}"
  end
end
```

```rb 1,3,5,7,9 title="Or, use a dedicated gem"
require "async"

Async.do |task|
  %w[pikachu squirtle].each do |name|
    task.async do
      URI.open "https://pokeapi.co/api/v2/pokemon/#{name}"
    end
  end
end
```

</CodeSurfer>

---

# BYOSI

- Bring Your Own Scheduling Interface
- Ruby stdlib doesn't provide one by default
- [Fiber::SchedulerInterface](https://ruby-doc.org/core-3.1.1/Fiber/SchedulerInterface.html)

<Notes>
  - Even though Ruby doesn't provide one out of the box, non-blocking Fibers are supported by the Ruby stdlib, meaning most stdlib functions call out to schedulers on blocking i/o.
</Notes>

---

# What about existing code?

---

<img src={ioChanges} />

---

# Summarized, Why Fibers?

- Lighter-weight than Threads
- Spin up more Fibers on the same system
- Less context switching
- SchedulerInterface = Ruby stdlib compatibility

---

# Rails?

- ActiveRecord is a problem
- [Make ActiveRecord::ConnectionPool Fiber-safe](https://github.com/rails/rails/pull/44219)
- Lots of code still dependent on Threads

---

# Better support for fiber-aware servers

<CodeSurfer>

```rb
config.active_support.isolation_level = :fiber
```

</CodeSurfer>

---

# References

Check out the [README](https://github.com/mgmarlow/fibers#readme)
